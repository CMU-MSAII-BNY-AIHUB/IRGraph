{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\BNY Mellon capstone project\\BKG\\data\\sample_rtf\\Northern Trust Corporation, Q1 2020 Earnings Call, Apr 21, 2020.rtf\n",
      "e:\\BNY Mellon capstone project\\BKG\\data\\sample_rtf\\State Street Corporation, Q4 2019 Earnings Call, Jan 17, 2020.rtf\n",
      "e:\\BNY Mellon capstone project\\BKG\\data\\sample_rtf\\The Bank of New York Mellon Corporation, Q2 2023 Earnings Call, Jul 18, 2023 (1).rtf\n",
      "e:\\BNY Mellon capstone project\\BKG\\data\\sample_rtf\\The Bank of New York Mellon Corporation, Q3 2020 Earnings Call, Oct 16, 2020.rtf\n",
      "e:\\BNY Mellon capstone project\\BKG\\data\\sample_rtf\\The Bank of New York Mellon Corporation, Q3 2023 Earnings Call, Oct 17, 2023 (1).rtf\n",
      "e:\\BNY Mellon capstone project\\BKG\\data\\sample_rtf\\The Bank of New York Mellon Corporation, Q4 2023 Earnings Call, Jan 12, 2024 (1).rtf\n"
     ]
    }
   ],
   "source": [
    "rtf_path = os.path.abspath('sample_rtf')\n",
    "xml_path = os.path.abspath('sample_xml')\n",
    "for root, dirs, files in os.walk(rtf_path):\n",
    "        for file in files:\n",
    "            print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = \"State Street Corporation, Q4 2019 Earnings Call, Jan 17, 2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<aspose.words.saving.SaveOutputParameters object at 0x0000025CB3703B10>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import aspose.words as aw\n",
    "doc = aw.Document(os.path.join(rtf_path, filename+\".rtf\"))\n",
    "doc.save(filename+\".docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc = docx.Document(filename+\".docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'State Street Corporation'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename.split(\",\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_columns(arr):\n",
    "    transposed = list(zip(*arr))\n",
    "\n",
    "    filtered = [col for col in transposed if any(cell != \"\" for cell in col)]\n",
    "\n",
    "    return list(zip(*filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_list = {}\n",
    "\n",
    "def compare_entities(name1, name2):\n",
    "    return fuzz.ratio(name1, name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_ambigity(speaker_list,person_info):\n",
    "    exist = False\n",
    "    for p in speaker_list:\n",
    "        similarity_score = compare_entities(p[\"name\"], person_info[\"name\"]) * compare_entities(p[\"company\"], person_info[\"company\"]) / 10000\n",
    "        if similarity_score > 0.65:\n",
    "            exist = True\n",
    "            print(p, person_info, similarity_score)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_first_table(data):\n",
    "    data = [list(dict.fromkeys(row)) for row in data]\n",
    "    data = remove_empty_columns(data)\n",
    "    root = ET.Element(\"table\",attrib={\"id\":\"0\", \"name\":\"Earnings Estimates Comparison Table\"})\n",
    "\n",
    "    time_periods = ET.SubElement(root, \"timePeriods\")\n",
    "    for period in data[0][1:]:\n",
    "        ET.SubElement(time_periods, \"period\", name=period.replace(\"-\", \"\"))\n",
    "\n",
    "    metrics = ET.SubElement(root, \"metrics\")\n",
    "    for metric_data in data[2:]:\n",
    "        metric = ET.SubElement(metrics, \"metric\", name=metric_data[0])\n",
    "        for i, value in enumerate(metric_data[1:]):\n",
    "            period_name = data[0][i + 1]\n",
    "            value_type = data[1][i + 1]\n",
    "            ET.SubElement(metric, \"value\", period=period_name, type=value_type).text = value\n",
    "    \n",
    "    return root\n",
    "\n",
    "def build_second_table(data):\n",
    "    # clean duplicates   \n",
    "    data = [list(dict.fromkeys(row)) for row in data]\n",
    "    data = remove_empty_columns(data)\n",
    "    \n",
    "    root = ET.Element(\"table\",attrib={\"id\":\"1\",\"name\":\"EPS Normalized Comparison Table\"})\n",
    "    \n",
    "\n",
    "    type_header = data[1]\n",
    "\n",
    "    time_periods = ET.SubElement(root, \"timePeriods\") \n",
    "    metrics = ET.SubElement(root, \"metrics\") \n",
    "    metric = ET.SubElement(metrics, \"metric\", name=\"EPS Normalized\")\n",
    "    for row in data[2:]:\n",
    "        period = row[0]\n",
    "        ET.SubElement(time_periods, \"period\", name=period)\n",
    "        for i, cell in enumerate(row[1:], 1):\n",
    "            type_ = type_header[i]  \n",
    "            if type_ in [\"CONSENSUS\", \"ACTUAL\", \"SURPRISE\"]:\n",
    "                value_element = ET.SubElement(metric, \"value\")\n",
    "                value_element.text = cell\n",
    "                value_element.set(\"period\", period)\n",
    "                value_element.set(\"type\", type_)\n",
    "\n",
    "    return root\n",
    "\n",
    "def build_third_table(data,company):\n",
    "    id = 1\n",
    "    root = ET.Element(\"Call Participants\")\n",
    "    # speaker_list = {}\n",
    "         \n",
    "    current_group = ''\n",
    "    for row in data[1:]:\n",
    "        \n",
    "        row_data = '\\n \\n \\n'.join(row).strip()\n",
    "        elements = row_data.split('\\n \\n \\n')\n",
    "        for element in elements:\n",
    "\n",
    "            lines = element.split('\\n')\n",
    "\n",
    "            if len(lines) == 1 :\n",
    "                current_group = lines[0].strip()\n",
    "                \n",
    "            if len(lines) > 1:\n",
    "\n",
    "                name = re.sub(r'\\s+', ' ', lines[0].strip())\n",
    "                person_info = {}\n",
    "                position = lines[1].strip()\n",
    "                origin_position = position\n",
    "                if current_group == \"EXECUTIVES\":\n",
    "                    person_element = ET.SubElement(root, \"person\", company = company, position=position, group=current_group, id = str(id))\n",
    "                    person_info[\"company\"] = company\n",
    "                    person_info[\"position\"] = position\n",
    "\n",
    "                    \n",
    "                else:\n",
    "                    position = position.replace(\"Research Division\", \"\").strip()\n",
    "                    if position[-1] == \",\":\n",
    "                        position = position[:-1].strip()\n",
    "                    person_element = ET.SubElement(root, \"person\", company = position, group=current_group, id = str(id))\n",
    "                    person_info[\"company\"] = position\n",
    "\n",
    "                    \n",
    "                    \n",
    "                person_element.text = name\n",
    "                person_info[\"name\"] = name\n",
    "        \n",
    "                person_info[\"id\"] = str(id)\n",
    "                              \n",
    "                person_info[\"origin position\"] = origin_position\n",
    "                \n",
    "                speaker_list[name] = person_info\n",
    "                id+=1\n",
    "    return root, speaker_list\n",
    "\n",
    "\n",
    "def process_presentation(dialog,speaker_list, name):\n",
    "    paragraph = dialog.split('\\n')\n",
    "\n",
    "    conversation = ET.Element(\"section\", attrib={\"name\": name})\n",
    "    i = 0 \n",
    "    while i < len(paragraph):\n",
    "        speaker_name = re.sub(r'\\s+', ' ', paragraph[i].strip())\n",
    "        if speaker_name  in speaker_list:\n",
    "            id = speaker_list[speaker_name][\"id\"]\n",
    "            title = paragraph[i+1].strip()\n",
    "            \n",
    "            if title != speaker_list[speaker_name][\"origin position\"]:\n",
    "                origin_position = speaker_list[speaker_name][\"origin position\"]\n",
    "                parts = title.split(origin_position)\n",
    "                other_part = parts[1] if len(parts) > 1 else \"\"\n",
    "                \n",
    "                text = other_part.strip() + \"\\n\" if other_part!=\"\" else \"\"\n",
    "            else:\n",
    "                text = \"\"\n",
    "            \n",
    "            statement = ET.SubElement(conversation, \"statement\")\n",
    "            speaker_element = ET.SubElement(statement, \"speaker\", id=id, position=speaker_list[speaker_name][\"origin position\"])\n",
    "            speaker_element.text = re.sub(r'\\s+', ' ', paragraph[i].strip()) \n",
    "            para = ET.SubElement(speaker_element, \"text\")\n",
    "            i += 2\n",
    "            while i < len(paragraph) and re.sub(r'\\s+', ' ', paragraph[i].strip()) not in speaker_list and paragraph[i].strip()!= \"Operator\":\n",
    "                if len(paragraph[i].strip()) != 0:\n",
    "                    text += paragraph[i] + \"\\n\"\n",
    "                i += 1\n",
    "            \n",
    "            para.text = text.strip()\n",
    "            \n",
    "        elif \"Operator\" in paragraph[i]:\n",
    "            id = \"0\"\n",
    "            position = \"Operator\"\n",
    "            statement = ET.SubElement(conversation, \"statement\")\n",
    "            speaker_element = ET.SubElement(statement, \"speaker\", id=id, position=position)\n",
    "            speaker_element.text = \"Operator\"\n",
    "            text = \"\"\n",
    "            para = ET.SubElement(speaker_element, \"text\")\n",
    "            i += 1\n",
    "            while i < len(paragraph) and re.sub(r'\\s+', ' ', paragraph[i].strip()) not in speaker_list:\n",
    "                if len(paragraph[i].strip()) != 0:\n",
    "                    text += paragraph[i] + \"\\n\"\n",
    "                i += 1\n",
    "            para.text = text.strip()\n",
    "            \n",
    "        else:\n",
    "            i += 1\n",
    "    return conversation\n",
    "\n",
    "\n",
    "def process_dialog(dialog,speaker_list, name):\n",
    "    question_id = -1\n",
    "    followup_id = -1\n",
    "    end = False\n",
    "    paragraph = dialog.split('\\n')\n",
    "    cur_question = None\n",
    "    conversation = ET.Element(\"section\", attrib={\"name\": name})\n",
    "    i = 0 \n",
    "    hasSub = False\n",
    "    last_question_element = None\n",
    "    last_question_answered = True\n",
    "    while i < len(paragraph):\n",
    "        speaker_name = re.sub(r'\\s+', ' ', paragraph[i].strip())\n",
    "        if speaker_name in speaker_list:\n",
    "            id = speaker_list[speaker_name][\"id\"]\n",
    "            title = paragraph[i+1].strip()\n",
    "            if title != speaker_list[speaker_name][\"origin position\"]:\n",
    "                origin_position = speaker_list[speaker_name][\"origin position\"]\n",
    "                parts = title.split(origin_position)\n",
    "                other_part = parts[1] if len(parts) > 1 else \"\"\n",
    "                \n",
    "                text = other_part.strip() + \"\\n\" if other_part!=\"\" else \"\"\n",
    "            else:\n",
    "                text = \"\"\n",
    "            if end:\n",
    "                context = ET.SubElement(conversation, \"ending\", id = str(question_id))\n",
    "                \n",
    "            elif cur_question == None:\n",
    "                if last_question_element is not None and not last_question_answered:\n",
    "                    if last_question_element.tag ==\"question\":\n",
    "                        question_id-=1\n",
    "                    last_question_element.tag = \"other\"\n",
    "                followup_id = -1\n",
    "                context = ET.SubElement(conversation, \"question\", id = str(question_id))\n",
    "                cur_question = paragraph[i].strip()\n",
    "                last_question_element = context\n",
    "                last_question_answered = False\n",
    "            elif paragraph[i].strip() == cur_question :\n",
    "                if last_question_element is not None and not last_question_answered:\n",
    "                    if last_question_element.tag ==\"question\":\n",
    "                        question_id-=1\n",
    "                    elif last_question_element.tag ==\"followQuestion\":\n",
    "                        print(last_question_element.tag)\n",
    "                        followup_id -=1\n",
    "                    last_question_element.tag = \"other\"\n",
    "\n",
    "                followup_id += 1\n",
    "                context = ET.SubElement(conversation, \"followQuestion\", id=str(followup_id),  question_id = str(question_id))\n",
    "                hasSub = True\n",
    "                last_question_element = context\n",
    "                last_question_answered = False\n",
    "            elif hasSub and paragraph[i].strip()!= cur_question:\n",
    "                context = ET.SubElement(conversation, \"followAnswer\", id=str(followup_id),  question_id = str(question_id))\n",
    "                hasSub = False\n",
    "                last_question_answered = True\n",
    "            else:\n",
    "                context = ET.SubElement(conversation, \"answer\", id = str(question_id))\n",
    "                last_question_answered = True\n",
    "            speaker_element = ET.SubElement(context, \"speaker\", id=id, position=speaker_list[speaker_name][\"origin position\"])\n",
    "            speaker_element.text = re.sub(r'\\s+', ' ', paragraph[i].strip()) \n",
    "            \n",
    "            para = ET.SubElement(speaker_element, \"text\")\n",
    "            i += 2\n",
    "            while i < len(paragraph) and re.sub(r'\\s+', ' ', paragraph[i].strip()) not in speaker_list and paragraph[i].strip()!= \"Operator\" and not paragraph[i].startswith(\"Operator\"):\n",
    "                # print(paragraph[i])\n",
    "                # print(paragraph[i].startswith(\"Operator\"))\n",
    "                # print(\"--------------------------\")\n",
    "                if len(paragraph[i].strip()) != 0:\n",
    "                    text += paragraph[i] + \"\\n\"\n",
    "                i += 1\n",
    "            para.text = text.strip()\n",
    "            \n",
    "        elif \"Operator\" in paragraph[i]:\n",
    "            if last_question_element is not None and not last_question_answered:\n",
    "                if last_question_element.tag ==\"question\":\n",
    "                    question_id-=1\n",
    "                last_question_element.tag = \"other\"\n",
    "            last_question_element = None\n",
    "            last_question_answered = False\n",
    "            id = \"0\"\n",
    "            position = \"Operator\"\n",
    "            cur_question = None\n",
    "            hasSub = False\n",
    "            question_id += 1\n",
    "            followup_id = -1\n",
    "            context =ET.SubElement(conversation, \"transition\") \n",
    "            speaker_element = ET.SubElement(context, \"speaker\", id=id, position=position)\n",
    "            speaker_element.text = \"Operator\"\n",
    "            text = \"\"\n",
    "            para = ET.SubElement(speaker_element, \"text\")\n",
    "            paragraph[i] = paragraph[i].replace(\"Operator\", \"\")\n",
    "            while i < len(paragraph) and re.sub(r'\\s+', ' ', paragraph[i].strip())  not in speaker_list:\n",
    "                if len(paragraph[i].strip()) != 0:\n",
    "                    text += paragraph[i] + \"\\n\"\n",
    "                i += 1\n",
    "            para.text = text.strip()\n",
    "            if \"conclude\" in para.text:\n",
    "                context.tag = \"ending\"\n",
    "                end = True\n",
    "                \n",
    "            \n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify(element, indent='    ', level=0):\n",
    "    \n",
    "    if element:  \n",
    "        if not element.text or not element.text.strip():\n",
    "            element.text = '\\n' + indent * (level + 1)\n",
    "        if not element.tail or not element.tail.strip():\n",
    "            element.tail = '\\n' + indent * level\n",
    "    else:\n",
    "        if level and (not element.tail or not element.tail.strip()):\n",
    "            element.tail = '\\n' + indent * level\n",
    "    \n",
    "    for subelement in element:\n",
    "        prettify(subelement, indent, level + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = \"\"\n",
    "for i, paragraph in enumerate(doc.paragraphs):\n",
    "\n",
    "    if i ==2 :\n",
    "        company = paragraph.text\n",
    "        break\n",
    "tables = []\n",
    "for table_index, table in enumerate(doc.tables):\n",
    "        t = []\n",
    "        for row_index, row in enumerate(table.rows):\n",
    "            row_data = []\n",
    "\n",
    "           \n",
    "            for cell in row.cells:\n",
    "                row_data.append(cell.text.strip())\n",
    "\n",
    "            if all(element == \"\" for element in row_data):\n",
    "                 continue\n",
    "            t.append(row_data)\n",
    "        if t== [['']] or t ==[]:\n",
    "             continue\n",
    "        tables.append(t)\n",
    "        \n",
    "t1 = build_first_table(tables[0])\n",
    "t2 = build_second_table(tables[1])\n",
    "t3,speaker_list = build_third_table(tables[3],company)\n",
    "sec1 = ET.Element(\"section\", attrib={\"name\": \"Financial Tables\"})\n",
    "sec1.append(t1)\n",
    "sec1.append(t2)\n",
    "t3.tag = \"section\"\n",
    "t3.set(\"name\", \"Call Participants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime,timedelta\n",
    "def get_stock_info(ticker_symbol, time):\n",
    "    open = None\n",
    "    close = None\n",
    "\n",
    "    try:\n",
    "        ticker = yf.Ticker(ticker_symbol)\n",
    "\n",
    "\n",
    "        date_str = time\n",
    "        date_format = \"%A, %B %d, %Y %I:%M %p %Z\"\n",
    "        datetime_obj = datetime.strptime(date_str, date_format)\n",
    "\n",
    "        formatted_date = datetime_obj.strftime(\"%Y-%m-%d\")\n",
    "        datetime_obj_plus_one = datetime_obj + timedelta(days=1)\n",
    "        print(formatted_date)\n",
    "        data = ticker.history(start=formatted_date, end=datetime_obj_plus_one)\n",
    "\n",
    "        if not data.empty:\n",
    "            open =  data['Open'][0]\n",
    "            close = data['Close'][0]\n",
    "        else:\n",
    "            print(\"No data available for the specified date.\")\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "    return open,close\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-17\n",
      "Friday, January 17, 2020 3:00 PM GMT\n"
     ]
    }
   ],
   "source": [
    "body = ET.Element(\"body\")\n",
    "company = \"\"\n",
    "title = \"\"\n",
    "time = \"\"\n",
    "currency = \"\"\n",
    "note = \"\"\n",
    "QA = None\n",
    "presentation = None\n",
    "for i, paragraph in enumerate(doc.paragraphs):\n",
    "\n",
    "    if i ==2 :\n",
    "        company = paragraph.text\n",
    "        \n",
    "    elif i == 3:\n",
    "        title = paragraph.text\n",
    "    elif i == 4:\n",
    "        time = paragraph.text\n",
    "    elif i == 6:\n",
    "        currency= paragraph.text\n",
    "    elif i == 7:\n",
    "        note= paragraph.text\n",
    "    \n",
    "    elif paragraph.text.strip().startswith(\"Question and Answer\"):\n",
    "        QA = process_dialog(paragraph.text,speaker_list,\"Question and Answer\")\n",
    "    elif paragraph.text.strip().startswith(\"Presentation\"):\n",
    "        \n",
    "        presentation = process_presentation(paragraph.text,speaker_list,\"Presentation \")\n",
    "    \n",
    "header = ET.Element(\"header\")\n",
    "ticker = company.split(\":\")[1].strip()\n",
    "match = re.search(r\"Q\\d \\d{4}\", title)\n",
    "q_y = match.group(0).replace(\" \", \"-\") if match else \"No match found\"\n",
    "quarter, year = q_y.split(\"-\")\n",
    "ET.SubElement(header, \"company\").text = company\n",
    "ET.SubElement(header, \"quarter\").text = quarter\n",
    "ET.SubElement(header, \"year\").text = year\n",
    "ET.SubElement(header, \"time\").text = time\n",
    "ET.SubElement(header, \"currency\").text = currency\n",
    "ET.SubElement(header, \"note\").text = note\n",
    "ET.SubElement(header, \"ticker\").text = ticker\n",
    "open, close = get_stock_info(ticker,time)\n",
    "ET.SubElement(header, \"stock_price_before\").text =  f\"{open:.6f}\"\n",
    "ET.SubElement(header, \"stock_price_after\").text = f\"{close:.6f}\"\n",
    "if abs(close - open) <=1:\n",
    "    performance = \"neutral\"\n",
    "elif (close - open) < 0:\n",
    "    performance = \"negative\"\n",
    "else:\n",
    "    performance = \"positive\"\n",
    "ET.SubElement(header, \"stock_performance\").text = performance\n",
    "print(time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-17\n"
     ]
    }
   ],
   "source": [
    "open, close = get_stock_info(ticker,time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "body.append(sec1)\n",
    "body.append(t3)\n",
    "body.append(presentation)\n",
    "body.append(QA)\n",
    "root = ET.Element(\"Transcript\")\n",
    "root.append(header)\n",
    "root.append(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = ET.Element(\"body\")\n",
    "# sec1 = ET.Element(\"section\", attrib={\"name\": \"financial tables\"})\n",
    "# t1 = build_first_table(tables[0])\n",
    "# t2 = build_second_table(tables[1])\n",
    "# t3,speaker_list = build_third_table(tables[3])\n",
    "# sec1.append(t1)\n",
    "# sec1.append(t2)\n",
    "# t3.tag = \"section\"\n",
    "# t3.set(\"name\", \"call participants\")\n",
    "# root.append(header)\n",
    "# root.append(sec1)\n",
    "# root.append(t3)\n",
    "\n",
    "\n",
    "prettify(root)\n",
    "\n",
    "\n",
    "tree = ET.ElementTree(root)\n",
    "\n",
    "\n",
    "out_file_name = f\"{ticker}-{quarter}-{year}\"\n",
    "\n",
    "tree.write(os.path.join(xml_path,out_file_name+\".xml\"), encoding=\"utf-8\", xml_declaration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(filename+'.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Eric Walter Aboaf': {'company': 'State Street Corporation NYSE:STT',\n",
       "  'position': 'Executive VP & CFO',\n",
       "  'name': 'Eric Walter Aboaf',\n",
       "  'id': '1',\n",
       "  'origin position': 'Executive VP & CFO'},\n",
       " 'Ilene Fiszel Bieler': {'company': 'State Street Corporation NYSE:STT',\n",
       "  'position': 'Global Head of Investor Relations',\n",
       "  'name': 'Ilene Fiszel Bieler',\n",
       "  'id': '2',\n",
       "  'origin position': 'Global Head of Investor Relations'},\n",
       " 'Ronald Philip O’Hanley': {'company': 'State Street Corporation NYSE:STT',\n",
       "  'position': 'Chairman, President & CEO',\n",
       "  'name': 'Ronald Philip O’Hanley',\n",
       "  'id': '3',\n",
       "  'origin position': 'Chairman, President & CEO'},\n",
       " 'Alexander Blostein': {'company': 'Goldman Sachs Group Inc.',\n",
       "  'name': 'Alexander Blostein',\n",
       "  'id': '4',\n",
       "  'origin position': 'Goldman Sachs Group Inc., Research Division'},\n",
       " 'Betsy Lynn Graseck': {'company': 'Morgan Stanley',\n",
       "  'name': 'Betsy Lynn Graseck',\n",
       "  'id': '5',\n",
       "  'origin position': 'Morgan Stanley, Research Division'},\n",
       " 'Brennan Hawken': {'company': 'UBS Investment Bank',\n",
       "  'name': 'Brennan Hawken',\n",
       "  'id': '6',\n",
       "  'origin position': 'UBS Investment Bank, Research Division'},\n",
       " 'Brian Bertram Bedell': {'company': 'Deutsche Bank AG',\n",
       "  'name': 'Brian Bertram Bedell',\n",
       "  'id': '7',\n",
       "  'origin position': 'Deutsche Bank AG, Research Division'},\n",
       " 'Brian Matthew Kleinhanzl': {'company': 'Keefe, Bruyette, & Woods, Inc.',\n",
       "  'name': 'Brian Matthew Kleinhanzl',\n",
       "  'id': '8',\n",
       "  'origin position': 'Keefe, Bruyette, & Woods, Inc., Research Division'},\n",
       " 'Gerard S. Cassidy': {'company': 'RBC Capital Markets',\n",
       "  'name': 'Gerard S. Cassidy',\n",
       "  'id': '9',\n",
       "  'origin position': 'RBC Capital Markets, Research Division'},\n",
       " 'Glenn Paul Schorr': {'company': 'Evercore ISI Institutional Equities',\n",
       "  'name': 'Glenn Paul Schorr',\n",
       "  'id': '10',\n",
       "  'origin position': 'Evercore ISI Institutional Equities, Research Division'},\n",
       " 'James Francis Mitchell': {'company': 'The Buckingham Research Group Incorporated',\n",
       "  'name': 'James Francis Mitchell',\n",
       "  'id': '11',\n",
       "  'origin position': 'The Buckingham Research Group Incorporated'},\n",
       " 'Kenneth Michael Usdin': {'company': 'Jefferies LLC',\n",
       "  'name': 'Kenneth Michael Usdin',\n",
       "  'id': '12',\n",
       "  'origin position': 'Jefferies LLC, Research Division'},\n",
       " 'Michael Lawrence Mayo': {'company': 'Wells Fargo Securities, LLC',\n",
       "  'name': 'Michael Lawrence Mayo',\n",
       "  'id': '13',\n",
       "  'origin position': 'Wells Fargo Securities, LLC, Research Division'},\n",
       " 'Michael Roger Carrier': {'company': 'BofA Merrill Lynch',\n",
       "  'name': 'Michael Roger Carrier',\n",
       "  'id': '14',\n",
       "  'origin position': 'BofA Merrill Lynch, Research Division'},\n",
       " 'Robert Henry Wildhack': {'company': 'Autonomous Research LLP',\n",
       "  'name': 'Robert Henry Wildhack',\n",
       "  'id': '15',\n",
       "  'origin position': 'Autonomous Research LLP'}}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_imaging' from 'PIL' (c:\\Users\\xiaomi\\anaconda3\\envs\\BKG\\lib\\site-packages\\PIL\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BytesIO\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_and_open_images\u001b[39m(docx_filename):\n",
      "File \u001b[1;32mc:\\Users\\xiaomi\\anaconda3\\envs\\BKG\\lib\\site-packages\\PIL\\Image.py:84\u001b[0m\n\u001b[0;32m     75\u001b[0m MAX_IMAGE_PIXELS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# If the _imaging C module is not present, Pillow will not load.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# Note that other modules should not refer to _imaging directly;\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# import Image and use the Image.core variable instead.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# Also note that Image.core is not a publicly documented interface,\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# and should be considered private and subject to change.\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _imaging \u001b[38;5;28;01mas\u001b[39;00m core\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m __version__ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(core, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     87\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe _imaging extension was built for another version of Pillow or PIL:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCore version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(core,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPillow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     91\u001b[0m         )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_imaging' from 'PIL' (c:\\Users\\xiaomi\\anaconda3\\envs\\BKG\\lib\\site-packages\\PIL\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# import zipfile\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# from io import BytesIO\n",
    "\n",
    "# def extract_and_open_images(docx_filename):\n",
    "\n",
    "#     temp_dir = \"extracted_images\"\n",
    "#     os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "#     with zipfile.ZipFile(docx_filename, 'r') as docx:\n",
    "\n",
    "#         for file in docx.namelist():\n",
    "#             if file.startswith('word/media/'):\n",
    "#                 image_data = docx.read(file)\n",
    "#                 image = Image.open(BytesIO(image_data))\n",
    "#                 image.show()  \n",
    "\n",
    "\n",
    "#                 image_filename = os.path.join(temp_dir, os.path.basename(file))\n",
    "#                 image.save(image_filename)\n",
    "\n",
    "\n",
    "# docx_filename = filename+'.docx'  \n",
    "# extract_and_open_images(docx_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
