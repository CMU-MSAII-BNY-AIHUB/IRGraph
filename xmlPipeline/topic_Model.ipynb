{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2tSotrOcjAVi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# !unzip -uq \"/content/xml_w_sentiment.zip\" -d \"/content/xml_w_sentiment\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f_1YUiuOjO5-"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv(\"bny.csv\")\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N035KY3zjTNj"
      },
      "outputs": [],
      "source": [
        "# topics = list(pd.DataFrame(Data.groupby(['category']).agg(Count = ('category','count'))['Count']\\\n",
        "#                            .nlargest(6)).reset_index()['category'])\n",
        "\n",
        "topics = ['NII (net interest income)','Deposit', 'Investment', 'Third-Party-Product','Revenue', 'New-Tech']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3l5NUmlUk7o3"
      },
      "outputs": [],
      "source": [
        "# !pip install openai\n",
        "# !pip install openai==0.28\n",
        "# tried this: https://medium.com/@stephensonebinezer/transform-your-topic-modeling-with-chatgpt-cutting-edge-nlp-f4654b4eac99\n",
        "# but it gave a couple of errors related to the model type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "N0BVGm-floRT"
      },
      "outputs": [],
      "source": [
        "# import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NG64eP_Fk6c0"
      },
      "outputs": [],
      "source": [
        "# import openai as ai\n",
        "\n",
        "# # Get the key from an environment variable on the machine it is running on\n",
        "# ai.api_key = \"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\"\n",
        "\n",
        "# #function to return the queried response\n",
        "# def generate_gpt3_response(user_text, print_output=False):\n",
        "#     \"\"\"\n",
        "#     Query OpenAI GPT-3 for the specific key and get back a response\n",
        "#     :type user_text: str the user's text to query for\n",
        "#     :type print_output: boolean whether or not to print the raw output JSON\n",
        "#     \"\"\"\n",
        "#     time.sleep(5)\n",
        "#     completions = ai.Completion.create(\n",
        "#         engine='gpt-3.5-turbo-1106',  # Determines the quality, speed, and cost.\n",
        "#         temperature=0.5,            # Level of creativity in the response\n",
        "#         prompt=user_text,           # What the user typed in\n",
        "#         max_tokens=500,             # Maximum tokens in the prompt AND response\n",
        "#         n=1,                        # The number of completions to generate\n",
        "#         stop=None,                  # An optional setting to control response generation\n",
        "#     )\n",
        "\n",
        "#     # Displaying the output can be helpful if things go wrong\n",
        "#     if print_output:\n",
        "#         print(completions)\n",
        "\n",
        "#     # Return the first choice's text\n",
        "#     return completions.choices[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gVzuFXUPlkaX"
      },
      "outputs": [],
      "source": [
        "# df['GPT'] = df['Question'].apply(lambda x: \\\n",
        "#               generate_gpt3_response\\\n",
        "#               (\"I am giving you the title and a question asked in a financial meeting \\\n",
        "#                 give me the Broader category like 'NII (net interest income)','Deposit', 'Investment', 'Third-Party-Product','Revenue', 'New-Tech',\\\n",
        "#                or the related high level topics in one word in the \\\n",
        "#                 format[Topic: your primary topic] for the text '{}' \".format(x)))\n",
        "\n",
        "# #Cleaning the output as it is from ChatGPT\n",
        "# # df['GPT'] = df['GPT'].apply(lambda x: (x.split(':')[1]).replace(']',''))\\\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW8ovoMgmWSR",
        "outputId": "55c8e044-fb36-463b-e35a-e860acaafdeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.1.0rc1-py3-none-any.whl (117 kB)\n",
            "     -------------------------------------- 117.3/117.3 kB 2.3 MB/s eta 0:00:00\n",
            "Collecting google-ai-generativelanguage==0.1.0\n",
            "  Downloading google_ai_generativelanguage-0.1.0-py3-none-any.whl (109 kB)\n",
            "     -------------------------------------- 109.3/109.3 kB 3.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.1.0->google-generativeai) (2.11.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.1.0->google-generativeai) (1.22.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.1.0->google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.1.0->google-generativeai) (2.14.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.1.0->google-generativeai) (1.56.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.1.0->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.1.0->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.1.0->google-generativeai) (1.54.0)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.1.0->google-generativeai) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.1.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.1.0->google-generativeai) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.1.0->google-generativeai) (0.2.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.1.0->google-generativeai) (2.0.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.1.0->google-generativeai) (1.26.16)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.1.0->google-generativeai) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.1.0->google-generativeai) (2022.12.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\coooo\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.1.0->google-generativeai) (0.4.8)\n",
            "Installing collected packages: google-ai-generativelanguage, google-generativeai\n",
            "Successfully installed google-ai-generativelanguage-0.1.0 google-generativeai-0.1.0rc1\n"
          ]
        }
      ],
      "source": [
        "!pip install google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImCGKNviSkpj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "v3_xOIj2m8FI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\coooo\\anaconda3\\envs\\final project\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as palm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4FxpJqwMm-KE"
      },
      "outputs": [],
      "source": [
        "palm.configure(api_key = \"AIzaSyDfNrwPU9x3ZkQZpRbih-GRXrlDtjALc7A\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "o_fZl5b4m_6V"
      },
      "outputs": [],
      "source": [
        "def response(input):\n",
        "  # Set up the model\n",
        "  generation_config = {\n",
        "    \"temperature\": 0.9,\n",
        "    \"top_p\": 1,\n",
        "    \"top_k\": 1,\n",
        "    \"max_output_tokens\": 2048,\n",
        "  }\n",
        "\n",
        "  safety_settings = [\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "  ]\n",
        "\n",
        "  model = palm.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "                                generation_config=generation_config,\n",
        "                                safety_settings=safety_settings)\n",
        "\n",
        "  prompt_parts = [\n",
        "    \"I am giving you a question asked in a financial meeting  give me the Broader topic like 'NII (net interest income)','Deposit', 'Investment', 'Third-Party-Product','Revenue', 'New-Tech',   or the related high level topic.\",\n",
        "    #\"input: Just a quick\\n  follow-up first maybe around the deposit discussion. So Dermot, if I hear you\\n  correctly, no kind of catch-up from the back book that you expect to see in\\n  your deposit pricing for the rest of the year. But I guess, if we look at the\\n  deposit beta over the course of this quarter, it looks like it was pretty\\n  close to 100% on a currency adjusted basis. Maybe help us break down the\\n  deposit cost in U.S. and non-U.S. and maybe the type of -- what kind of\\n  deposit pressure and client conversations are you seeing in the kind of\\n  different regions?\",\n",
        "    \"input:\"+input,\n",
        "  # \"output: \",\n",
        "  ]\n",
        "\n",
        "  # print(input)\n",
        "\n",
        "  response = model.generate_content(prompt_parts)\n",
        "  return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "BXbZ7174n2-W"
      },
      "outputs": [],
      "source": [
        "# df['topic'] = df['Question'].apply(response)\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgSHkMscoNOK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "raDpw5GQ6RjK"
      },
      "outputs": [],
      "source": [
        "from xml.etree import ElementTree as ET\n",
        "import pandas as pd\n",
        "import torch\n",
        "def extract_qa_text(xml_file_path):\n",
        "    # Load the XML file\n",
        "    tree = ET.parse(xml_file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Define empty lists to store speaker IDs, names, positions, and question texts\n",
        "    speaker_id_list = []\n",
        "    speaker_name_list = []\n",
        "    speaker_position_list = []\n",
        "    text_list = []\n",
        "\n",
        "    # Find all question elements\n",
        "    questions = root.findall(\".//question\")\n",
        "\n",
        "    # Iterate through each question element\n",
        "    for question in questions:\n",
        "        speaker_element = question.find(\"speaker\")\n",
        "        if speaker_element is not None:\n",
        "            speaker_id = speaker_element.attrib.get(\"id\")\n",
        "            speaker_name = speaker_element.text\n",
        "            speaker_position = speaker_element.attrib.get(\"position\")\n",
        "            text = speaker_element.find(\"text\").text.strip()\n",
        "            # Append speaker info and question text to lists\n",
        "            speaker_id_list.append(speaker_id)\n",
        "            speaker_name_list.append(speaker_name)\n",
        "            speaker_position_list.append(speaker_position)\n",
        "            text_list.append(text)\n",
        "\n",
        "    # Create DataFrame\n",
        "    qa_df = pd.DataFrame({\n",
        "        'Speaker ID': speaker_id_list,\n",
        "        'Speaker Name': speaker_name_list,\n",
        "        'Speaker Position': speaker_position_list,\n",
        "        'Question Text': text_list\n",
        "    })\n",
        "\n",
        "    return qa_df\n",
        "\n",
        "def add_topic_tag_to_xml(xml_file_path, qa_df, file_name):\n",
        "    tree = ET.parse(xml_file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    qa_section = root.find(\"./body/section[@name='Question and Answer']\")\n",
        "       # qa_section = root.find(\"./body/section[@name='Question and Answer']\")\n",
        "\n",
        "    # Iterate through question elements in the XML\n",
        "    for idx, element in enumerate(qa_section.iter('question')):\n",
        "        # Add sentiment label to corresponding text element\n",
        "        text_element = element.find(\"speaker/text\")\n",
        "        if text_element is not None:\n",
        "            sentiment_element = ET.SubElement(text_element, \"topic\")\n",
        "            sentiment_element.text = qa_df.loc[idx, 'topic']\n",
        "    tree.write(file_name, encoding='utf-8', xml_declaration=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "W6hAvqezTSLw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "def process_xml_files(input_folder, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".xml\"):\n",
        "            output_file_path = os.path.join(output_folder, filename)\n",
        "            if os.path.exists(output_file_path):\n",
        "                continue\n",
        "            \n",
        "            file_path = os.path.join(input_folder, filename)\n",
        "            print(f\"Processing {file_path}...\")\n",
        "\n",
        "            # Extract Q&A session\n",
        "            qa_df = extract_qa_text(file_path)\n",
        "            print('extracted')\n",
        "\n",
        "            # Conduct topic analysis\n",
        "            qa_df['topic'] = qa_df['Question Text'].apply(response)\n",
        "            print('topic')\n",
        "            # Add the report as a tag to the XML file\n",
        "            output_file_path = os.path.join(output_folder, filename)\n",
        "            add_topic_tag_to_xml(file_path, qa_df, output_file_path)\n",
        "            print(f\"Processed {file_path}. Result saved at {output_file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sWKU1xl6Uceu",
        "outputId": "1f4b7c14-59d5-437e-ac8c-901cc0c25563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing xml_w_sentiment\\BK-Q1-2018.xml...\n",
            "extracted\n",
            "topic\n",
            "Processed xml_w_sentiment\\BK-Q1-2018.xml. Result saved at xml_w_sentiment_topic\\BK-Q1-2018.xml\n",
            "Processing xml_w_sentiment\\BK-Q1-2019.xml...\n",
            "extracted\n",
            "topic\n",
            "Processed xml_w_sentiment\\BK-Q1-2019.xml. Result saved at xml_w_sentiment_topic\\BK-Q1-2019.xml\n",
            "Processing xml_w_sentiment\\BK-Q1-2020.xml...\n",
            "extracted\n",
            "topic\n",
            "Processed xml_w_sentiment\\BK-Q1-2020.xml. Result saved at xml_w_sentiment_topic\\BK-Q1-2020.xml\n",
            "Processing xml_w_sentiment\\BK-Q1-2021.xml...\n",
            "extracted\n",
            "topic\n",
            "Processed xml_w_sentiment\\BK-Q1-2021.xml. Result saved at xml_w_sentiment_topic\\BK-Q1-2021.xml\n",
            "Processing xml_w_sentiment\\BK-Q1-2022.xml...\n",
            "extracted\n",
            "topic\n",
            "Processed xml_w_sentiment\\BK-Q1-2022.xml. Result saved at xml_w_sentiment_topic\\BK-Q1-2022.xml\n",
            "Processing xml_w_sentiment\\BK-Q1-2023.xml...\n",
            "extracted\n",
            "topic\n",
            "Processed xml_w_sentiment\\BK-Q1-2023.xml. Result saved at xml_w_sentiment_topic\\BK-Q1-2023.xml\n",
            "Processing xml_w_sentiment\\BK-Q2-2018.xml...\n",
            "extracted\n",
            "topic\n",
            "Processed xml_w_sentiment\\BK-Q2-2018.xml. Result saved at xml_w_sentiment_topic\\BK-Q2-2018.xml\n",
            "Processing xml_w_sentiment\\BK-Q2-2019.xml...\n",
            "extracted\n",
            "topic\n",
            "Processed xml_w_sentiment\\BK-Q2-2019.xml. Result saved at xml_w_sentiment_topic\\BK-Q2-2019.xml\n",
            "Processing xml_w_sentiment\\BK-Q2-2020.xml...\n",
            "extracted\n",
            "topic\n",
            "Processed xml_w_sentiment\\BK-Q2-2020.xml. Result saved at xml_w_sentiment_topic\\BK-Q2-2020.xml\n",
            "Processing xml_w_sentiment\\BK-Q2-2021.xml...\n",
            "extracted\n",
            "topic\n",
            "Processed xml_w_sentiment\\BK-Q2-2021.xml. Result saved at xml_w_sentiment_topic\\BK-Q2-2021.xml\n",
            "Processing xml_w_sentiment\\BK-Q2-2022.xml...\n",
            "extracted\n",
            "topic\n",
            "Processed xml_w_sentiment\\BK-Q2-2022.xml. Result saved at xml_w_sentiment_topic\\BK-Q2-2022.xml\n",
            "Processing xml_w_sentiment\\BK-Q2-2023.xml...\n",
            "extracted\n",
            "topic\n",
            "Processed xml_w_sentiment\\BK-Q2-2023.xml. Result saved at xml_w_sentiment_topic\\BK-Q2-2023.xml\n",
            "Processing xml_w_sentiment\\BK-Q3-2018.xml...\n",
            "extracted\n"
          ]
        },
        {
          "ename": "ResourceExhausted",
          "evalue": "429 Resource has been exhausted (e.g. check quota).",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\coooo\\anaconda3\\envs\\final project\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:72\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "File \u001b[1;32mc:\\Users\\coooo\\anaconda3\\envs\\final project\\lib\\site-packages\\grpc\\_channel.py:1030\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1028\u001b[0m state, call, \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[0;32m   1029\u001b[0m                               wait_for_ready, compression)\n\u001b[1;32m-> 1030\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\coooo\\anaconda3\\envs\\final project\\lib\\site-packages\\grpc\\_channel.py:910\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[1;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
            "\u001b[1;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Resource has been exhausted (e.g. check quota).\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.250.80.42:443 {created_time:\"2024-04-01T02:04:43.096741461+00:00\", grpc_status:8, grpc_message:\"Resource has been exhausted (e.g. check quota).\"}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxml_w_sentiment\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxml_w_sentiment_topic\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mprocess_xml_files\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[28], line 17\u001b[0m, in \u001b[0;36mprocess_xml_files\u001b[1;34m(input_folder, output_folder)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextracted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Conduct topic analysis\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m qa_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mqa_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuestion Text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Add the report as a tag to the XML file\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\coooo\\anaconda3\\envs\\final project\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\coooo\\anaconda3\\envs\\final project\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\coooo\\anaconda3\\envs\\final project\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
            "File \u001b[1;32mc:\\Users\\coooo\\anaconda3\\envs\\final project\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
            "Cell \u001b[1;32mIn[25], line 42\u001b[0m, in \u001b[0;36mresponse\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m     33\u001b[0m prompt_parts \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     34\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI am giving you a question asked in a financial meeting  give me the Broader topic like \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNII (net interest income)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeposit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvestment\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThird-Party-Product\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRevenue\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew-Tech\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,   or the related high level topic.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     35\u001b[0m   \u001b[38;5;66;03m#\"input: Just a quick\\n  follow-up first maybe around the deposit discussion. So Dermot, if I hear you\\n  correctly, no kind of catch-up from the back book that you expect to see in\\n  your deposit pricing for the rest of the year. But I guess, if we look at the\\n  deposit beta over the course of this quarter, it looks like it was pretty\\n  close to 100% on a currency adjusted basis. Maybe help us break down the\\n  deposit cost in U.S. and non-U.S. and maybe the type of -- what kind of\\n  deposit pressure and client conversations are you seeing in the kind of\\n  different regions?\",\u001b[39;00m\n\u001b[0;32m     36\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# \"output: \",\u001b[39;00m\n\u001b[0;32m     38\u001b[0m ]\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# print(input)\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_parts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtext\n",
            "File \u001b[1;32mc:\\Users\\coooo\\anaconda3\\envs\\final project\\lib\\site-packages\\google\\generativeai\\generative_models.py:232\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, request_options)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 232\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m    233\u001b[0m         request,\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options,\n\u001b[0;32m    235\u001b[0m     )\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
            "File \u001b[1;32mc:\\Users\\coooo\\anaconda3\\envs\\final project\\lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:566\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    561\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m (\n\u001b[0;32m    562\u001b[0m     gapic_v1\u001b[38;5;241m.\u001b[39mrouting_header\u001b[38;5;241m.\u001b[39mto_grpc_metadata(((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmodel),)),\n\u001b[0;32m    563\u001b[0m )\n\u001b[0;32m    565\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 566\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[1;32mc:\\Users\\coooo\\anaconda3\\envs\\final project\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:113\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata)\n\u001b[0;32m    111\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\coooo\\anaconda3\\envs\\final project\\lib\\site-packages\\google\\api_core\\retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    346\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    348\u001b[0m )\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\coooo\\anaconda3\\envs\\final project\\lib\\site-packages\\google\\api_core\\retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "File \u001b[1;32mc:\\Users\\coooo\\anaconda3\\envs\\final project\\lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\coooo\\anaconda3\\envs\\final project\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:74\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
            "\u001b[1;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota)."
          ]
        }
      ],
      "source": [
        "input='xml_w_sentiment'\n",
        "output='xml_w_sentiment_topic'\n",
        "process_xml_files(input,output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K2JkIqy8rFV"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # extract statements from the presentation\n",
        "    file_name = 'BNY-Q3-2020'\n",
        "    xml_file_path = '/content/With_Sentiment_The Bank of New York Mellon Corporation, Q3 2020 Earnings Call, Oct 16, 2020.xml'\n",
        "    # print(f\"\\n## Extracting Q&A session from {xml_file_path}...\")\n",
        "    qa_df = extract_qa_text(xml_file_path)\n",
        "    #/content/With_Sentiment_The Bank of New York Mellon Corporation, Q3 2020 Earnings Call, Oct 16, 2020.xml\n",
        "    qa_df['topic'] = qa_df['Question Text'].apply(response)\n",
        "    # print(\"\\n## Adding the report as a tag to the XML file...\")\n",
        "    output_file = 'with_sentiment_with_topic_the_bank_of_new_york_mellon_corporation__q3_2020_earnings_call__oct_16__2020.xml'\n",
        "    add_topic_tag_to_xml(xml_file_path, qa_df, output_file)\n",
        "    # print(f\"Done! Find the XML file here:{output_file} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJeE7s8483t3",
        "outputId": "bf6cc3a4-5609-497f-ff8f-c42955be1c7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All files processed and zipped successfully!\n"
          ]
        }
      ],
      "source": [
        "def zip_folder(folder_to_zip, zip_file_name):\n",
        "    shutil.make_archive(zip_file_name, 'zip', folder_to_zip)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # input_folder = 'sample_xml'\n",
        "    output_folder = '/content/xml_w_sentiment_topic'\n",
        "    # process_xml_files(input_folder, output_folder)\n",
        "    # Zip the output folder\n",
        "    zip_folder(output_folder, 'processed_xml_with_topics')\n",
        "\n",
        "    print(\"All files processed and zipped successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GelrIa4PmBjZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
